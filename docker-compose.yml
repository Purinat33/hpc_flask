services:
  # prometheus:
  #   image: prom/prometheus:latest
  #   container_name: prometheus
  #   volumes:
  #     - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
  #   command: ["--config.file=/etc/prometheus/prometheus.yml"]
  #   ports:
  #     - "9090:9090"
  #   restart: unless-stopped

  # grafana:
  #   image: grafana/grafana:latest
  #   container_name: grafana
  #   ports:
  #     - "3000:3000"
  #   volumes:
  #     - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
  #     - ./grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
  #     - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
  #   environment:
  #     - GF_SECURITY_ADMIN_USER=admin
  #     - GF_SECURITY_ADMIN_PASSWORD=admin
  #   depends_on:
  #     - prometheus
  #   restart: unless-stopped
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    ports:
      - "11434:11434"
    volumes:
      - ollama:/root/.ollama
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "sh", "-c", "ollama list >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 12
      start_period: 10s



  # Optional: pull models once on startup
  ollama-init:
    image: ollama/ollama:latest
    container_name: ollama-init
    depends_on:
      ollama:
        condition: service_started     # we'll poll until it's ready
    environment:
      - OLLAMA_HOST=http://ollama:11434
    # Run a small shell script (no YAML folding/quotes issues)
    entrypoint:
      - sh
      - -lc
      - |
        set -e
        while ! ollama list >/dev/null 2>&1; do
          sleep 1
        done
        ollama pull llama3.2
        ollama pull nomic-embed-text
    restart: "no"



  pg:
    image: postgres:16
    container_name: pg
    ports:
      - "5433:5432"
    environment:
      POSTGRES_USER: hpc_user
      POSTGRES_PASSWORD: muict
      POSTGRES_DB: hpc_app
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U hpc_user -d hpc_app"]
      interval: 5s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  adminer:
    image: adminer:latest
    container_name: adminer
    ports:
      - "8080:8080"
    depends_on:
      - pg
    restart: unless-stopped

  hpc:
    build: .
    container_name: hpc
    volumes:
      # Option A: mount the whole folder
      - ./instance:/app/instance
      # Option B: mount just the file
      # - ./instance/test.csv:/app/instance/test.csv:ro
    # The app talks to Postgres over the Docker network (service name "pg")
    environment:
      DATABASE_URL: postgresql+psycopg2://hpc_user:muict@pg:5432/hpc_app
      FLASK_SECRET_KEY: change-me
      APP_ENV: development
      # any others you use:
      ADMIN_PASSWORD: rosebud
      SEED_DEMO_USERS: "1"
      FALLBACK_CSV: /app/instance/test.csv # Set to whatever file you want
      LOG_TO_STDOUT: "1"
      DEMO_USERS: gable:gable:user,alice:alice:user,bob:bob:user,akara.sup:12345678:user,surapol.gits:12345:user,phakee.tra:54321:user,kanjana.las:12345:user,root:toor:admin
      OLLAMA_BASE_URL: http://ollama:11434
      COPILOT_ENABLED: "1"
      COPILOT_LLM: llama3.2
      COPILOT_EMBED_MODEL: nomic-embed-text
      COPILOT_DOCS_DIR: /app/docs
      COPILOT_INDEX_DIR: /app/instance/copilot_index   # persisted in your instance/
      COPILOT_TOP_K: "6"        # how many chunks to send to the LLM
      COPILOT_MIN_SIM: "0.28"   # below this → “I don’t know”
      COPILOT_RATE_LIMIT_PER_MIN: "12"  # per IP
    depends_on:
      pg:
        condition: service_healthy
      ollama:
        condition: service_started
      ollama-init:
        condition: service_completed_successfully
      
    ports:
      - "8000:8000"  # host:container; you hit http://localhost:8000
    command: gunicorn -b 0.0.0.0:8000 --timeout 600 --graceful-timeout 30 --access-logfile - --error-logfile - wsgi:app
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request,sys; sys.exit(0 if urllib.request.urlopen('http://127.0.0.1:8000/readyz', timeout=2).getcode()==200 else 1)\""]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 15s

  swagger:
    image: swaggerapi/swagger-ui:latest
    container_name: swagger
    environment:
      SWAGGER_JSON: /spec/openapi.yaml
    volumes:
      - ./docs/api:/spec:ro
    ports:
      - "8081:8080"
    restart: unless-stopped

  mkdocs:
    build:
      context: .
      dockerfile: Dockerfile.mkdocs
    container_name: mkdocs
    working_dir: /docs
    volumes:
      - ./mkdocs.yml:/docs/mkdocs.yml:ro
      - ./docs:/docs/docs:ro
    ports:
      - "9999:9999"    # pick any host port ≥ 9000
    restart: unless-stopped



volumes:
  pgdata:
  ollama:
  copilot_index: 
